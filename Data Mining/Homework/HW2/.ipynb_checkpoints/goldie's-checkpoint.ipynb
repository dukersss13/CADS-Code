{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Implement a function that takes in the *train.csv* dataset and returns a cleaned dataset without outliers and NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.066</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.00040</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.063</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.99608</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.116</td>\n",
       "      <td>26.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.99722</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.098</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.00040</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           12.0              0.37         0.76             4.2      0.066   \n",
       "1            7.1              0.69         0.08             2.1      0.063   \n",
       "2            9.6              0.50         0.36             2.8      0.116   \n",
       "3            7.7              0.96         0.20             2.0      0.047   \n",
       "5           11.9              0.38         0.49             2.7      0.098   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                  7.0                  38.0  1.00040  3.22       0.60   \n",
       "1                 42.0                  52.0  0.99608  3.42       0.60   \n",
       "2                 26.0                  55.0  0.99722  3.18       0.68   \n",
       "3                 15.0                  60.0  0.99550  3.36       0.44   \n",
       "5                 12.0                  42.0  1.00040  3.16       0.61   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     13.0        7  \n",
       "1     10.2        6  \n",
       "2     10.9        5  \n",
       "3     10.9        5  \n",
       "5     10.3        5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "def preprocessing_pipeline(train):\n",
    "    ## Your code goes here\n",
    "    train = train.dropna() #removes all NAs\n",
    "    train = train.drop(columns=['Id'], axis=1) #remove ID column, unnecessay \n",
    "    \n",
    "    #remove outliers\n",
    "    for column in train:\n",
    "        \n",
    "        # Calculate the mean and standard deviation\n",
    "        mu = np.mean(train[column])\n",
    "        std = np.std(train[column])\n",
    "\n",
    "        # Normalize the data\n",
    "        normalized_data = (train[column] - mu)/std\n",
    "\n",
    "        # Find the data index that is 3 standard deviation away from the distribution\n",
    "        indexes = normalized_data < 3\n",
    "        train = train.loc[indexes, :]\n",
    "        processed_train = train\n",
    "    \n",
    "    return processed_train\n",
    "train_clean = preprocessing_pipeline(train)\n",
    "train_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Implement a function that takes in the R<sup>2</sup> of a regression and return the VIF value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(r_squared):\n",
    "    ## Your code goes here\n",
    "    vif = 1/(1-r_squared)\n",
    "    \n",
    "    return vif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Implement a function that takes in preprocessed data and returns a dataframe that contains the VIF for each variable. The dataframe should contain two columns: variable names and their VIFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vif_dataframe(processed_train):\n",
    "    ## Your code goes here\n",
    "    newData = []\n",
    "    columnArray = []\n",
    "\n",
    "    vif_train = processed_train.drop(['quality'], axis = 1)\n",
    "    columns = vif_train.columns\n",
    "    \n",
    "    for col in columns:\n",
    "        \n",
    "        columnArray = [col]\n",
    "        X = vif_train.drop(col,axis=1).values\n",
    "        y = vif_train[col].values\n",
    "        \n",
    "        #calculate regression\n",
    "        heights_constant_added = sm.add_constant(X)\n",
    "        results = sm.OLS(y, heights_constant_added).fit()\n",
    "        r2 = results.rsquared\n",
    "        \n",
    "        vif = round(calculate_vif(r2), 3)\n",
    "        columnArray.append(vif)\n",
    "        newData.append(columnArray)\n",
    "        \n",
    "        vif_dataframe = pd.DataFrame(newData, columns = ['Variable', 'VIF'])   \n",
    "    \n",
    "    \n",
    "    return vif_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Use the functions that you developed from Q1 and generate a VIF dataframe for all the variables in the wine dataset. Discuss the VIF values you find and the effect of multicollinearity on regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>fixed acidity</td>\n",
       "      <td>7.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>volatile acidity</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>citric acid</td>\n",
       "      <td>3.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>residual sugar</td>\n",
       "      <td>1.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>chlorides</td>\n",
       "      <td>1.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>free sulfur dioxide</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>total sulfur dioxide</td>\n",
       "      <td>2.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>density</td>\n",
       "      <td>6.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>pH</td>\n",
       "      <td>3.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>sulphates</td>\n",
       "      <td>1.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>2.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Variable    VIF\n",
       "0          fixed acidity  7.884\n",
       "1       volatile acidity  1.875\n",
       "2            citric acid  3.209\n",
       "3         residual sugar  1.651\n",
       "4              chlorides  1.183\n",
       "5    free sulfur dioxide  1.976\n",
       "6   total sulfur dioxide  2.204\n",
       "7                density  6.251\n",
       "8                     pH  3.231\n",
       "9              sulphates  1.253\n",
       "10               alcohol  2.992"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code goes here\n",
    "generate_vif_dataframe(train_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion goes here\n",
    "\n",
    "#There are 2 variables where their VIF is > 5, this means that multicollinearity is present in my model. Fixed Acidity has a VIF\n",
    "#of 7.884 and Density has a VIF of 6.251. Multicollinearity means that 2 or more predictor variables are highly correlated.\n",
    "#This is typically bad because it effects our judgement as to which variables are important to our overall model. \n",
    "#Multicollinearity also means that there is weak support for our regression plane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Use the VIF dataframe you generated from Q1 and choose a subset of variables that does not have high multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volatile acidity         0.690\n",
       "citric acid              0.080\n",
       "residual sugar           2.100\n",
       "chlorides                0.063\n",
       "free sulfur dioxide     42.000\n",
       "total sulfur dioxide    52.000\n",
       "pH                       3.420\n",
       "sulphates                0.600\n",
       "alcohol                 10.200\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code goes here\n",
    "\n",
    "#subset of variables that do not have high multicollinearity i.e. VIF < 5 (took out fixed acidity and density)\n",
    "\n",
    "X = train_clean[[\"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\",\"pH\", \"sulphates\",\"alcohol\"]]\n",
    "#X = train_clean[[\"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\",\"pH\", \"sulphates\",\"alcohol\",\"quality\"]]\n",
    "#X = train_clean[[\"volatile acidity\", \"citric acid\",\"pH\", \"sulphates\",\"alcohol\"]]\n",
    "#train_clean_droplowMC = \n",
    "#generate_vif_dataframe(X)\n",
    "X.head()\n",
    "X.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fit a multiple linear regression model and print a summary of the regression result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   68.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 15 Feb 2020</td> <th>  Prob (F-statistic):</th> <td>1.03e-97</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:25:19</td>     <th>  Log-Likelihood:    </th> <td> -945.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   995</td>      <th>  AIC:               </th> <td>   1910.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   985</td>      <th>  BIC:               </th> <td>   1959.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    4.2764</td> <td>    0.613</td> <td>    6.980</td> <td> 0.000</td> <td>    3.074</td> <td>    5.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.0243</td> <td>    0.153</td> <td>   -6.682</td> <td> 0.000</td> <td>   -1.325</td> <td>   -0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -0.3771</td> <td>    0.157</td> <td>   -2.397</td> <td> 0.017</td> <td>   -0.686</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0088</td> <td>    0.024</td> <td>    0.363</td> <td> 0.717</td> <td>   -0.039</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -2.5190</td> <td>    0.999</td> <td>   -2.521</td> <td> 0.012</td> <td>   -4.479</td> <td>   -0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0040</td> <td>    0.003</td> <td>    1.318</td> <td> 0.188</td> <td>   -0.002</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0026</td> <td>    0.001</td> <td>   -2.536</td> <td> 0.011</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>   -0.6287</td> <td>    0.173</td> <td>   -3.642</td> <td> 0.000</td> <td>   -0.967</td> <td>   -0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    1.4980</td> <td>    0.173</td> <td>    8.683</td> <td> 0.000</td> <td>    1.159</td> <td>    1.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.3245</td> <td>    0.023</td> <td>   14.287</td> <td> 0.000</td> <td>    0.280</td> <td>    0.369</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 6.378</td> <th>  Durbin-Watson:     </th> <td>   2.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.041</td> <th>  Jarque-Bera (JB):  </th> <td>   8.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.003</td> <th>  Prob(JB):          </th> <td>  0.0152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.449</td> <th>  Cond. No.          </th> <td>2.77e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.385\n",
       "Model:                            OLS   Adj. R-squared:                  0.379\n",
       "Method:                 Least Squares   F-statistic:                     68.45\n",
       "Date:                Sat, 15 Feb 2020   Prob (F-statistic):           1.03e-97\n",
       "Time:                        15:25:19   Log-Likelihood:                -945.07\n",
       "No. Observations:                 995   AIC:                             1910.\n",
       "Df Residuals:                     985   BIC:                             1959.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    4.2764      0.613      6.980      0.000       3.074       5.479\n",
       "volatile acidity        -1.0243      0.153     -6.682      0.000      -1.325      -0.723\n",
       "citric acid             -0.3771      0.157     -2.397      0.017      -0.686      -0.068\n",
       "residual sugar           0.0088      0.024      0.363      0.717      -0.039       0.056\n",
       "chlorides               -2.5190      0.999     -2.521      0.012      -4.479      -0.559\n",
       "free sulfur dioxide      0.0040      0.003      1.318      0.188      -0.002       0.010\n",
       "total sulfur dioxide    -0.0026      0.001     -2.536      0.011      -0.005      -0.001\n",
       "pH                      -0.6287      0.173     -3.642      0.000      -0.967      -0.290\n",
       "sulphates                1.4980      0.173      8.683      0.000       1.159       1.837\n",
       "alcohol                  0.3245      0.023     14.287      0.000       0.280       0.369\n",
       "==============================================================================\n",
       "Omnibus:                        6.378   Durbin-Watson:                   2.073\n",
       "Prob(Omnibus):                  0.041   Jarque-Bera (JB):                8.372\n",
       "Skew:                          -0.003   Prob(JB):                       0.0152\n",
       "Kurtosis:                       3.449   Cond. No.                     2.77e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.77e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your code goes here\n",
    "y=train_clean[\"quality\"]\n",
    "\n",
    "results = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use 5-fold cross validation to validate the mean squared error (MSE) of a multiple linear regression model fit to the subset of data. (HINT: You will need to implement a function to calculate the MSE. See this link for more details: https://en.wikipedia.org/wiki/Mean_squared_error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([  0,   1,   4,   5,   7,   9,  10,  11,  12,  14,\\n            ...\\n            984, 985, 986, 987, 988, 990, 991, 992, 993, 994],\\n           dtype='int64', length=796)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a3e26ec04bc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#print(\"TRAIN:\", train_index, \"TEST:\", test_index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#print(X.loc[train_index])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([  0,   1,   4,   5,   7,   9,  10,  11,  12,  14,\\n            ...\\n            984, 985, 986, 987, 988, 990, 991, 992, 993, 994],\\n           dtype='int64', length=796)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "## Your code goes here\n",
    "\n",
    "#KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "kf = KFold(5, True, 1)\n",
    "kf.get_n_splits(X)\n",
    "#print(kf.split(X))\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    #print(X.loc[train_index])\n",
    "\n",
    "    \n",
    "results_kf = sm.OLS(y_train, sm.add_constant(X_train)).fit()\n",
    "print(results_kf.summary())\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#calculate_MSE(y_train, y_test)\n",
    "\n",
    "#X needs to be \"test\" set\n",
    "def calculate_MSE(y_train, y_test):\n",
    "    n = train_clean.shape[0] #number of observations\n",
    "    predictions = results.predict(X_test)\n",
    "    for i in range(n):\n",
    "       temp += ((y_train[i] - predictions[i])**2)\n",
    "    MSE = (1/n)*temp\n",
    "    return MSE\n",
    "#calculate_MSE(y, results)\n",
    "#predictions = results.predict(X)\n",
    "#predictions = np.array(results.predict(X))\n",
    "\n",
    "#for i in range(predictions):\n",
    "    #print (predictions[i])\n",
    "#print(predictions)\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Make a prediction on the test set using the model you fit in 2b and submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Compare the Kaggle score and the cross-validation result. Is the cross-validation result a good representation of the prediction accuracy on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Discuss the difference between goodness of fit on the training set, on the validation set, and on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your discussion here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
