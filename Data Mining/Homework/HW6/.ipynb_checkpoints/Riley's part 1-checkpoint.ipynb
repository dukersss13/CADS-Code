{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS530 Homework 6 Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "#from imblearn.metrics import sensitivity_specificity_support\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Files 'train.csv' and 'test.csv' contain data for the Heart Disease dataset. Use the scikit-learn package to train a logistic regression model on the training set, train.csv, and predict on the test set, test.csv. The variable that you are predicting is named 'target'. Give an accuracy of your prediction on the test set. You can find the description of the data in 'heart-disease.names' file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Duker\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here.\n",
    "df_train = pd.read_csv('train.csv', sep=',', index_col =0)\n",
    "df_train = df_train.dropna()\n",
    "X_train = df_train.drop(['target'], axis = 1)\n",
    "y_train = df_train['target']\n",
    "\n",
    "df_test = pd.read_csv('test.csv', sep=',', index_col =0)\n",
    "df_test = df_test.dropna()\n",
    "X_test = df_test.drop(['target'], axis = 1)\n",
    "y_test = df_test['target']\n",
    "\n",
    "log_reg = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
    "log_reg.predict(X_train)\n",
    "log_reg.predict_proba(X_train)\n",
    "log_reg.score(X_train,y_train)\n",
    "#84.6% accurate\n",
    "\n",
    "log_reg2 = LogisticRegression(random_state=0).fit(X_test,y_test)\n",
    "log_reg2.predict(X_test)\n",
    "log_reg2.predict_proba(X_test)\n",
    "log_reg2.score(X_test,y_test)\n",
    "#89.5% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use the scikit-learn package to plot an ROC curve of the predictions on the test set from 1a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code goes here.\n",
    "y_pred_prob = log_reg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred_prob)\n",
    "auc=metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='data, auc='+str(auc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Implement a function to plot the ROC curve of the model you get from on the test set. (Hints: 1. check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) of logistic regression to get the probability output. 2. Loop through a list of probability thresholds for classification and calculate the Specificity and Sensitivity for each threshold value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tpr       fpr\n",
       "0   0.000000  0.000000\n",
       "1   0.020833  0.000000\n",
       "2   0.395833  0.000000\n",
       "3   0.395833  0.035714\n",
       "4   0.562500  0.035714\n",
       "5   0.562500  0.071429\n",
       "6   0.645833  0.071429\n",
       "7   0.645833  0.107143\n",
       "8   0.708333  0.107143\n",
       "9   0.708333  0.142857\n",
       "10  0.895833  0.142857\n",
       "11  0.895833  0.178571\n",
       "12  0.937500  0.178571\n",
       "13  0.937500  0.214286\n",
       "14  0.958333  0.214286\n",
       "15  0.958333  0.250000\n",
       "16  0.979167  0.250000\n",
       "17  0.979167  0.500000\n",
       "18  1.000000  0.500000\n",
       "19  1.000000  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def roc_curve(predict_probabilities, thresholds):\n",
    "    tpr = predict_probabilities['tpr']\n",
    "    fpr = predict_probabilities['fpr']\n",
    "    for i in range(len(threshold)):\n",
    "        Sensitivity = tpr[i]\n",
    "        Specificity = 1 - fpr[i]\n",
    "        #print(Sensitivity, Specificity)\n",
    "    return\n",
    "\n",
    "predict_probabilities = pd.DataFrame({'tpr':tpr,'fpr':fpr})\n",
    "roc_curve(predict_probabilities, threshold)\n",
    "predict_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Use the same dataset in Question 1 to train a classification model with the LDA algorithm. Give a prediction accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Plot the ROC curve of the LDA model you trained in 2a on the test set. You can use the scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Compare the ROC and accuracy on the test set that you get from Questions 1 and 2. Which algorithm performs better on this dataset? Explain your answer and hypothesize why one algorithm might be better than the other on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
