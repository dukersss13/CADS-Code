plot(high, type = 'l', main = 'Highest Bitcoin Price from 6/19 - 5/20')
# As we can see, the TS plot doesn't necessarily show stationarity.
# To make sure we're working with a stationary data set, I want to difference it once.
high2 = diff(high,1)
par(mfrow = c(1,2))
plot(high2, type = 'l', main = 'Bitcoin Price, d = 1')
# The difference plot looks more stationary, we'll assume the spikes are outliers
# and view them as noise.
pacf(high2)
# The PACF suggests the first 2 lags are significant.
# The rest of the lags' correlations may be caused a factor of seasonality.
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
prices_100_days = arimaFunction(high, 100)
prices_100_days$mean[[100]]
prices_100_days
#futurePrice shows the forecast for Bitcoin price for the next 100 days.
#The price can range from ~$5k to $14k with an 80% confidence interval
#or $2.5k to $16.5k, a bigger range with a 95% confidence interval.
#The actual forecast is $9.5k.
#Now I want to compare the ARIMA(2,1,2) forecast to H.W Double Exponential Smoothing
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
pred = Holt(high, 100)
pred
pred$mean[100]
#Further analysis on the H.W model:
#Alpha = 1 tells us the future price has no depedence on the previous level &
#with a small Beta, it shows the prices of BTC heavily depend on the trend of the movements.
#The price recorded on 5/19 is $9685. I want to compare prediction vs. actual:
may19 = Holt(high, 3)
may19$mean[[3]]
#Prediction is $9677 vs. actual: $9675
pred$mean[[3]]
#ARIMA(2,1,2) predicted $9562 as the price for 5/19/20
#So far, we can see adding a trend (BETA) component to Double Exp. Smoothing
#helps us make a better prediction.
#Now I want to use the same process to analyze Litecoin, another type of altcoin.
data2 = read.table("litecoin.csv", sep = ',', header = TRUE)
lite = rev(data2[,3])
litecoin = ts(lite)
plot(litecoin, main = "Litecoin Prices")
#Similar to BTC, Litecoin doesn't seem to show stationarity.
lite100 = arimaFunction(litecoin, 100)
lite100
lite100$upper[100]
lite_HW = Holt(lite, 100)
lite_HW$upper[[100]]
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "NIO")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, NIO)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
firstStock = closing[[1]]
secondStock = closing[[2]]
acf(firstStock)
pacf(firstStock)
firstStock100 = arimaFunction(firstStock, 30)
firstStock100
HW.firstStock = Holt(firstStock, 30)
HW.firstStock
#HW.ino$upper
# Analysis on Inovio stock prices:
# Auto.arima suggests an AR model of order 3 and 1 difference, no MA part needed.
# The HW command provides a more flexible forecast with wider ranges than ARIMA.
# This could be simply because HW uses Double Exponential Smoothing & considers
# the trend of the data while ARIMA only considers the regression of the previous lags.
secondStock100 = arimaFunction(secondStock,30)
secondStock100
HW.secondStock = Holt(secondStock100, 30)
HW.secondStock
# With all these models, I took away that most TS data sets will not be stationary.
# To successfully model and forecast, usually a difference or 2 has to be done to
# ensure stationarity.
# Looking at the residuals for these TS data sets, the errors show a constant
# variance over time as they are all normally distributed with mean 0.
# As we all know, stocks and cryptocurrencies are always more volatile and
# unpredictable than typical data sets such as yearly rain. Thus, there was not
# a seasonal component I could've incorporated in the HoltWinters function.
install.packages("tidyverse")
df = data.frame(foo = 21:30, c = ('a','b','c','d','e'), stringAsFactors = F)
df
df = data.frame(foo = 21:30, bar = c('a','b','c','d','e'), stringAsFactors = F)
df
tbl = tibble(foo = 21:25, bar = c('a','b','c','d','e'))
tbl
install.packages(c("backports", "broom", "callr", "classInt", "concaveman", "data.table", "dbplyr", "dendextend", "devtools", "dplyr", "DT", "ellipsis", "FKF", "foreach", "forecast", "fs", "gganimate", "ggforce", "ggplot2", "git2r", "glmnet", "glue", "gower", "gplots", "grpreg", "gtools", "haven", "htmltools", "httpuv", "httr", "isoband", "janitor", "jsonlite", "knitr", "later", "libcoin", "lmtest", "locfit", "lubridate", "magick", "modelr", "openssl", "padr", "pillar", "pkgbuild", "pkgload", "plotly", "pls", "processx", "promises", "ps", "purrr", "quantmod", "raster", "rayrender", "rayshader", "Rcpp", "RcppArmadillo", "Rdpack", "recipes", "remotes", "reshape2", "rex", "rgdal", "rgl", "riingo", "rlang", "rmarkdown", "roxygen2", "rversions", "rvest", "scales", "sf", "shape", "shiny", "sp", "SQUAREM", "stringi", "sys", "tibble", "tidyquant", "tidyr", "tidyselect", "timetk", "tinytex", "TSA", "TSP", "TTR", "units", "usethis", "V8", "vctrs", "withr", "xfun", "xml2", "xts", "zip", "zoo"))
library(tibble)
install.packages("tibble")
install.packages("tibble")
install.packages(c("stringi", "TSA"))
library(tibble)
install.packages("tibble")
library(dplyr)
library(dbplyr)
install.packages("tibble")
install.packages("dplyr")
library(dplyr)
install.packages("stringi")
library(rmarkdown)
install.packages(c("rmarkdown", "knitr"))
HW.SRNE30 = Holt(SRNE, 30)
library(TSA)
library(forecast)
library(tidyverse)
library(sarima)
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "SHLL", "SRNE", "SQ", "TSLA")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, SHLL, SRNE, SQ, TSLA)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
SRNE = closing[[3]]
acf(SRNE)
pacf(SRNE)
SRNE30 = arimaFunction(SRNE, 30)
SRNE30
HW.SRNE30 = Holt(SRNE, 30)
HW.SRNE30
data(wcgs)
data(wcgs.dta)
## Problem 1)
m1 = c(79, 66, 57, 91, 42, 59)
m2 = c(71, 43, 58, 78, 20, 56)
data(wcgs)
library(foreign, lib.loc = "C:/Program Files/R/R-3.6.3/library")
install.packages("foreign")
fake_wcgs <- data.frame("Ppl" = c(1:8),
"Weights" = c(100,102,110,140,174,189,298,592),
"Group" = c(0,1,2,3,0,1,2,3))
fake_wcgs <- data.frame("Ppl" = c(1:8),
"Weights" = c(100,102,110,140,174,189,298,592),
"Group" = c(0,1,2,3,0,1,2,3))
fake_wcgs = data.frame("Ppl" = c(1:8),
"Weights" = c(100,102,110,140,174,189,298,592),
"Group" = c(0,1,2,3,0,1,2,3))
g0 <- fake_wcgs[,2][which(fake_wcgs[,3]==0)]
g1 <- fake_wcgs[,2][which(fake_wcgs[,3]==1)]
g2 <- fake_wcgs[,2][which(fake_wcgs[,3]==2)]
g3 <- fake_wcgs[,2][which(fake_wcgs[,3]==3)]
View(fake_wcgs)
fake_wcgs <- data.frame("Ppl" = c(1:12),
"Weights" = c(100,102,110,140,174,189,298,592,182,103,173,246),
"Group" = c(0,1,2,3,0,1,2,3,0,1,2,3))
g0 <- fake_wcgs[,2][which(fake_wcgs[,3]==0)]
g1 <- fake_wcgs[,2][which(fake_wcgs[,3]==1)]
g2 <- fake_wcgs[,2][which(fake_wcgs[,3]==2)]
g3 <- fake_wcgs[,2][which(fake_wcgs[,3]==3)]
barlett.test(Weights~Group, fake_wcgs)
bartlett.test(Weights~Group, fake_wcgs)
#2c)
anova(fake_wcgs)
#2c)
anova(fake_wcgs)
?lm
#2c)
anova(lm(Weights~Group, fake_wcgs))
anov <- aov(fake_wcgs$weight ~ fake_wcgs$group)
anov <- aov(fake_wcgs$Weights ~ fake_wcgs$Group)
anov
p_val_anov <- summary(anov)[[1]][["Pr(>F)"]][[1]]
anov <- aov(Weights ~ Group)
p_val_anov <- summary(anov)[[1]][["Pr(>F)"]][[1]]
p_val_anov
anov <- aov(Weights ~ Group)
p_val_anov <- summary(anov)[[1]][["Pr(>F)"]][[1]]
p_val_anov
anov
p_val_anov
#2c)
anova(lm(Weights~Group, fake_wcgs))
#2c)
anovaTest = anova(lm(Weights~Group, fake_wcgs))
p_val_anov = summary(anovaTest)[[1]][["Pr(>F)"]][[1]]
p_val_anov = summary(anovaTest)[[1]][["Pr(>F)"]]
p_val_anov = summary(anovaTest)[[1]]
p_val = summary(anovaTest)[[1]]
p_val
anovaTest
p_val[["Pr(>F)"]]
p_val["Pr(>F)"]
anovaTest$`Pr(>F)`
anovaTest$`Pr(>F)`[1]
anovaTest$'Pr(>F)'[1]
anovaTest$'Pr(>F)'[1]
anovaTest$`Mean Sq`/anovaTest$`Sum Sq`
anovaTest
51217/15672
bonf_pw_tt = pairwise.t.test(fake_wcgs$weight, fake_wcgs$group, p.adj = "bonf")
bonf_pw_tt = pairwise.t.test(fake_wcgs$Weights, fake_wcgs$Group, p.adj = "bonf")
bonnf_pw_tt
bonf_pw_tt
TukeyHSD(anovaTest)
j = aov(lm(Weights~Group, fake_wcgs))
TukeyHSD(j)
j = aov(lm(Weights~Group, data = fake_wcgs))
TukeyHSD(j)
j = lm(Weights~Group, data = fake_wcgs)
TukeyHSD(aov(j))
fake_wcgs <- data.frame("Ppl" = c(1:12),
"Weights" = c(100,102,110,140,174,189,298,592,182,103,173,246),
"Group" = c(0,1,2,3,0,1,2,3,0,1,2,3))
#2c)
anovaTest = anova(lm(Weights~Group, fake_wcgs))
anovaTest
anovaTest$'Pr(>F)'[1]
bonf_pw_tt = pairwise.t.test(fake_wcgs$Weights, fake_wcgs$Group, p.adj = "bonf")
bonf_pw_tt
HSD.test(anovaTest)
aov(Weights~Group, fake_wcgs)
av.lm = lm(av)
av = aov(Weights~Group, fake_wcgs)
av.lm = lm(av)
TukeyHSD(av.lm)
av = lm(Weights~Group, fake_wcgs)
av.lm = aov(av)
TukeyHSD(av.lm)
av = lm(Weights, fake_wcgs)
av.lm = aov(av)
TukeyHSD(av.lm)
kruskal.test(Weights~Group, data = fake_wcgs)
wilcox.test(fake_wcgs$Weights, fake_wcgs$Group, p.adj = "bonf")
#2a)
shapiro.test(fake_wcgs$Weights)
#2a)
shapiro.test(Weights~Group, fake_wcgs)
fake_wcgs$Weights
#2a)
shapiro.test(fake_wcgs$Weights)
?shapiro
?shapiro.test
library(TSA)
library(forecast)
library(tidyverse)
library(sarima)
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "SHLL", "SRNE", "SQ", "TSLA")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, SHLL, SRNE, SQ, TSLA)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
SRNE = closing[[3]]
acf(SRNE)
pacf(SRNE)
SRNE30 = arimaFunction(SRNE, 30)
SRNE30
HW.SRNE30 = Holt(SRNE, 30)
HW.SRNE30
SRNE = closing[[1]]
acf(SRNE)
pacf(SRNE)
SRNE30 = arimaFunction(SRNE, 30)
SRNE30
HW.SRNE30 = Holt(SRNE, 30)
HW.SRNE30
SRNE = closing[[4]]
acf(SRNE)
pacf(SRNE)
SRNE30 = arimaFunction(SRNE, 30)
SRNE30
HW.SRNE30 = Holt(SRNE, 30)
HW.SRNE30
WKHS = closing[[1]]
acf(SRNE)
WKHS = closing[[1]]
acf(WKHS)
pacf(WKHS)
WKHS30 = arimaFunction(WKHS, 30)
WKHS30
HW.WKHS30 = Holt(WKHS, 30)
HW.WKHS30
WKHS30 = arimaFunction(WKHS, 30)
WKHS30
library(TSA)
library(forecast)
library(tidyverse)
library(sarima)
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "SHLL", "SRNE", "SQ", "TSLA")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, SHLL, SRNE, SQ, TSLA)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
WKHS = closing[[1]]
acf(WKHS)
pacf(WKHS)
WKHS30 = arimaFunction(WKHS, 30)
WKHS30
HW.WKHS30 = Holt(WKHS, 30)
HW.WKHS30
WKHS30 = arimaFunction(WKHS, 30)
WKHS30
library(dplyr)
data(starwars)
data(starwars)
force(starwars)
View(starwars)
# Problem 1 ####
names(starwars)
table(starwars$species)
table1 = starwars %>%
filter(table(species) > 1)
spec = table(starwars$species)
spec
spec[13]
spec[13] > 1
table(starwars$species)
table1 = starwars %>%
for (i in spec){
if (i >= 3){
filter(i)
}
}
print(i)
for (i in spec){
print(i)
}
table1 = starwars %>%
group_by(species) %>%
filter(n() >=3)
View(table1)
spec
print(table1)
names(starwars)
# Problem 2 ####
characters = starwars %>%
filter(names)
characters = starwars$name
planets = starwars$homeworld
type = starwars$species
planets = starwars$homeworld
table(starwars$homeworld,starwars$species)
freq = table(starwars$homeworld,starwars$species)
?frequency
freq = frequency(table(starwars$homeworld,starwars$species))
freq
freq
freq = table(starwars$homeworld,starwars$species)
freq
mytable = table(starwars$homeworld,starwars$species)
margin.table(mytable, 1)
ftable(mytable, 1)
mytable
paste(type, planets)
mytable = table(combo)
combo = paste(type, planets)
mytable = table(combo)
mytable
?max
sort(mytable, decreasing = TRUE)
top3 = sort(mytable, decreasing = TRUE)[1:3]
top3
?dplyr
a.top3 = sort(mytable, decreasing = TRUE)[1:3]
a.top3
b.top3 = starwars %>%
group_by(combo)
b.top3 = starwars %>%
group_by(type, planets)
b.top3 = starwars %>%
group_by(species, homeworld)
b.top3
View(b.top3)
b.top3 = starwars %>%
group_by(species, homeworld) %>%
summarise(
n = n()
)
b.top3 = starwars %>%
group_by(species, homeworld) %>%
summarise(
n = n()
)
View(b.top3)
b.top3 = starwars %>%
group_by(species, homeworld) %>%
summarise(
n = n(),
arrange(desc(n))
)
b.top3 = starwars %>%
group_by(species, homeworld) %>%
summarise(
n = n()
) %>%
arrange(desc(n))
a.top3
b.top[1:3]
b.top3[1:3]
b.top3[,1:3]
b.top3[,1:3]
b.top3[1,3]
b.top3[1:,3]
b.top3[1:3,]
setwd("C:/Users/Duker/Desktop/Fall 2020/CS 614/Class Work/Group Module 1")
library(dplyr)
library(plyr)
library(ggplot2)
tips = read.csv("tips.csv")
attach(tips)
names(tips)
# Tip rate vs. Sex
tip.rate = TIP/TOTBILL
boxplot(tip.rate~time.day2, xlab = "Time & Day", ylab = "Tip Rate")
time.day = paste(TIME, DAY)
time.day2 = mapvalues(time.day, c("0 3", "0 4", "1 3", "1 4", "1 5", "1 6"),
c("Morning Thursday", "Morning Friday", "Night Thursday",
"Night Friday ", "Night Saturday ", "Night Sunday "))
boxplot(tip.rate~time.day2, xlab = "Time & Day", ylab = "Tip Rate")
model = lm(tip.rate~time.day, data = tips)
summary(model)
anova(model)
model = lm(tip.rate~TIME+DAY, data = tips)
summary(model)
anova(model)
model = lm(tip.rate~SEX+SMOKER, data = tips)
anova(model)
plot(tip.rate ~ tips$SIZE, data = tips, xlab = "Party Size", ylab ="Tip Rate")
boxplot(tip.rate ~ tips$SIZE, data = tips,xlab = "Party Size", ylab ="Tip Rate")
anova(lm(tip.rate~SIZE, data = tips))
plot(tip.rate ~ tips$SIZE, data = tips, xlab = "Party Size", ylab ="Tip Rate")
boxplot(tip.rate ~ tips$SIZE, data = tips,xlab = "Party Size", ylab ="Tip Rate")
anova(lm(tip.rate~SIZE, data = tips))
