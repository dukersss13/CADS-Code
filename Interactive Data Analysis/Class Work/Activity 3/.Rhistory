attach(data)
names(data)
# I choose to analyze the highest price of the day.
bitcoin = ts(data, start = c(1,length(data),1))
high = rev(bitcoin[,3])
plot(high, type = 'l', main = 'Highest Bitcoin Price from 6/19 - 5/20')
# As we can see, the TS plot doesn't necessarily show stationarity.
# To make sure we're working with a stationary data set, I want to difference it once.
high2 = diff(high,1)
par(mfrow = c(1,2))
plot(high2, type = 'l', main = 'Bitcoin Price, d = 1')
# The difference plot looks more stationary, we'll assume the spikes are outliers
# and view them as noise.
pacf(high2)
# The PACF suggests the first 2 lags are significant.
# The rest of the lags' correlations may be caused a factor of seasonality.
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
prices_100_days = arimaFunction(high, 100)
prices_100_days$mean[[100]]
prices_100_days
#futurePrice shows the forecast for Bitcoin price for the next 100 days.
#The price can range from ~$5k to $14k with an 80% confidence interval
#or $2.5k to $16.5k, a bigger range with a 95% confidence interval.
#The actual forecast is $9.5k.
#Now I want to compare the ARIMA(2,1,2) forecast to H.W Double Exponential Smoothing
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
pred = Holt(high, 100)
pred
pred$mean[100]
#Further analysis on the H.W model:
#Alpha = 1 tells us the future price has no depedence on the previous level &
#with a small Beta, it shows the prices of BTC heavily depend on the trend of the movements.
#The price recorded on 5/19 is $9685. I want to compare prediction vs. actual:
may19 = Holt(high, 3)
may19$mean[[3]]
#Prediction is $9677 vs. actual: $9675
pred$mean[[3]]
#ARIMA(2,1,2) predicted $9562 as the price for 5/19/20
#So far, we can see adding a trend (BETA) component to Double Exp. Smoothing
#helps us make a better prediction.
#Now I want to use the same process to analyze Litecoin, another type of altcoin.
data2 = read.table("litecoin.csv", sep = ',', header = TRUE)
lite = rev(data2[,3])
litecoin = ts(lite)
plot(litecoin, main = "Litecoin Prices")
#Similar to BTC, Litecoin doesn't seem to show stationarity.
lite100 = arimaFunction(litecoin, 100)
lite100
lite100$upper[100]
lite_HW = Holt(lite, 100)
lite_HW$upper[[100]]
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "CODX")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(INO, CODX)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
ino = closing[[1]]
codx = closing[[2]]
acf(ino)
pacf(ino)
ino100 = arimaFunction(ino, 30)
ino100
HW.ino = Holt(ino, 30)
HW.ino
#HW.ino$upper
# Analysis on Inovio stock prices:
# Auto.arima suggests an AR model of order 3 and 1 difference, no MA part needed.
# The HW command provides a more flexible forecast with wider ranges than ARIMA.
# This could be simply because HW uses Double Exponential Smoothing & considers
# the trend of the data while ARIMA only considers the regression of the previous lags.
codx100 = arimaFunction(codx,30)
codx100
HW.codx = Holt(codx, 30)
HW.codx
# With all these models, I took away that most TS data sets will not be stationary.
# To successfully model and forecast, usually a difference or 2 has to be done to
# ensure stationarity.
# Looking at the residuals for these TS data sets, the errors show a constant
# variance over time as they are all normally distributed with mean 0.
# As we all know, stocks and cryptocurrencies are always more volatile and
# unpredictable than typical data sets such as yearly rain. Thus, there was not
# a seasonal component I could've incorporated in the HoltWinters function.
stocks_list = c("WKHS", "NIO")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, NIO)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
ino = closing[[1]]
codx = closing[[2]]
acf(ino)
pacf(ino)
ino100 = arimaFunction(ino, 30)
ino100
HW.ino = Holt(ino, 30)
HW.ino
codx100 = arimaFunction(codx,30)
codx100
HW.codx = Holt(codx, 30)
HW.codx
firstStock = closing[[1]]
secondStock = closing[[2]]
acf(firstStock)
pacf(firstStock)
firstStock100 = arimaFunction(firstStock, 30)
firstStock100
HW.firstStock = Holt(firstStock, 30)
HW.firstStock
secondStock100 = arimaFunction(secondStock,30)
secondStock100
HW.secondStock = Holt(secondStock100, 30)
HW.secondStock
secondStock100 = arimaFunction(secondStock,30)
secondStock100
HW.secondStock = Holt(secondStock100, 30)
HW.secondStock
library(TSA)
library(forecast)
library(tidyverse)
library(sarima)
#For my project, I chose to study the trends of cryptocurrency and stock prices.
#My goal is to determine a model of best fit, use it to forecast future prices &
#compare those results to the Exponential Smoothing forecasting technique.
#BTC (Bitcoin) prices from June 2019 to 5/16/2020
data = read.table("bitcoin.csv", sep = ",", header = T)
attach(data)
names(data)
# I choose to analyze the highest price of the day.
bitcoin = ts(data, start = c(1,length(data),1))
high = rev(bitcoin[,3])
plot(high, type = 'l', main = 'Highest Bitcoin Price from 6/19 - 5/20')
# As we can see, the TS plot doesn't necessarily show stationarity.
# To make sure we're working with a stationary data set, I want to difference it once.
high2 = diff(high,1)
par(mfrow = c(1,2))
plot(high2, type = 'l', main = 'Bitcoin Price, d = 1')
# The difference plot looks more stationary, we'll assume the spikes are outliers
# and view them as noise.
pacf(high2)
# The PACF suggests the first 2 lags are significant.
# The rest of the lags' correlations may be caused a factor of seasonality.
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
prices_100_days = arimaFunction(high, 100)
prices_100_days$mean[[100]]
prices_100_days
#futurePrice shows the forecast for Bitcoin price for the next 100 days.
#The price can range from ~$5k to $14k with an 80% confidence interval
#or $2.5k to $16.5k, a bigger range with a 95% confidence interval.
#The actual forecast is $9.5k.
#Now I want to compare the ARIMA(2,1,2) forecast to H.W Double Exponential Smoothing
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
pred = Holt(high, 100)
pred
pred$mean[100]
#Further analysis on the H.W model:
#Alpha = 1 tells us the future price has no depedence on the previous level &
#with a small Beta, it shows the prices of BTC heavily depend on the trend of the movements.
#The price recorded on 5/19 is $9685. I want to compare prediction vs. actual:
may19 = Holt(high, 3)
may19$mean[[3]]
#Prediction is $9677 vs. actual: $9675
pred$mean[[3]]
#ARIMA(2,1,2) predicted $9562 as the price for 5/19/20
#So far, we can see adding a trend (BETA) component to Double Exp. Smoothing
#helps us make a better prediction.
#Now I want to use the same process to analyze Litecoin, another type of altcoin.
data2 = read.table("litecoin.csv", sep = ',', header = TRUE)
lite = rev(data2[,3])
litecoin = ts(lite)
plot(litecoin, main = "Litecoin Prices")
#Similar to BTC, Litecoin doesn't seem to show stationarity.
lite100 = arimaFunction(litecoin, 100)
lite100
lite100$upper[100]
lite_HW = Holt(lite, 100)
lite_HW$upper[[100]]
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "NIO")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, NIO)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
firstStock = closing[[1]]
secondStock = closing[[2]]
acf(firstStock)
pacf(firstStock)
firstStock100 = arimaFunction(firstStock, 30)
firstStock100
HW.firstStock = Holt(firstStock, 30)
HW.firstStock
#HW.ino$upper
# Analysis on Inovio stock prices:
# Auto.arima suggests an AR model of order 3 and 1 difference, no MA part needed.
# The HW command provides a more flexible forecast with wider ranges than ARIMA.
# This could be simply because HW uses Double Exponential Smoothing & considers
# the trend of the data while ARIMA only considers the regression of the previous lags.
secondStock100 = arimaFunction(secondStock,30)
secondStock100
HW.secondStock = Holt(secondStock100, 30)
HW.secondStock
# With all these models, I took away that most TS data sets will not be stationary.
# To successfully model and forecast, usually a difference or 2 has to be done to
# ensure stationarity.
# Looking at the residuals for these TS data sets, the errors show a constant
# variance over time as they are all normally distributed with mean 0.
# As we all know, stocks and cryptocurrencies are always more volatile and
# unpredictable than typical data sets such as yearly rain. Thus, there was not
# a seasonal component I could've incorporated in the HoltWinters function.
install.packages("tidyverse")
df = data.frame(foo = 21:30, c = ('a','b','c','d','e'), stringAsFactors = F)
df
df = data.frame(foo = 21:30, bar = c('a','b','c','d','e'), stringAsFactors = F)
df
tbl = tibble(foo = 21:25, bar = c('a','b','c','d','e'))
tbl
install.packages(c("backports", "broom", "callr", "classInt", "concaveman", "data.table", "dbplyr", "dendextend", "devtools", "dplyr", "DT", "ellipsis", "FKF", "foreach", "forecast", "fs", "gganimate", "ggforce", "ggplot2", "git2r", "glmnet", "glue", "gower", "gplots", "grpreg", "gtools", "haven", "htmltools", "httpuv", "httr", "isoband", "janitor", "jsonlite", "knitr", "later", "libcoin", "lmtest", "locfit", "lubridate", "magick", "modelr", "openssl", "padr", "pillar", "pkgbuild", "pkgload", "plotly", "pls", "processx", "promises", "ps", "purrr", "quantmod", "raster", "rayrender", "rayshader", "Rcpp", "RcppArmadillo", "Rdpack", "recipes", "remotes", "reshape2", "rex", "rgdal", "rgl", "riingo", "rlang", "rmarkdown", "roxygen2", "rversions", "rvest", "scales", "sf", "shape", "shiny", "sp", "SQUAREM", "stringi", "sys", "tibble", "tidyquant", "tidyr", "tidyselect", "timetk", "tinytex", "TSA", "TSP", "TTR", "units", "usethis", "V8", "vctrs", "withr", "xfun", "xml2", "xts", "zip", "zoo"))
library(tibble)
install.packages("tibble")
install.packages("tibble")
install.packages(c("stringi", "TSA"))
library(tibble)
install.packages("tibble")
library(dplyr)
library(dbplyr)
install.packages("tibble")
install.packages("dplyr")
library(dplyr)
install.packages("stringi")
library(rmarkdown)
install.packages(c("rmarkdown", "knitr"))
HW.SRNE30 = Holt(SRNE, 30)
library(TSA)
library(forecast)
library(tidyverse)
library(sarima)
arimaFunction = function(data, n){
model = auto.arima(data)
model
#auto.arima confirms that the data set needs to be differenced once.
#It provides the best ARIMA model with AR(2), MA(2) & d = 1.
print(checkresiduals(model))
#The residuals show the data set with difference = 1.
futurePrice = forecast(model, h = n)
return(futurePrice)
}
Holt = function(data,n){
par(mfrow = c(1,1))
HW = HoltWinters(data, gamma = FALSE)
prediction = forecast(HW, h = n)
plot(HW)
print(HW$alpha)
print(HW$beta)
return(prediction)
}
#Lastly, I want to analyze Inovio & Co-Diagnostics stocks.
library(quantmod)
stocks_list = c("WKHS", "SHLL", "SRNE", "SQ", "TSLA")
for (i in stocks_list){
getSymbols(i,from = "2020-01-01", to = Sys.Date())
}
stocks = list(WKHS, SHLL, SRNE, SQ, TSLA)
closing = lapply(stocks, function(s) {
return(s[, 4])
})
SRNE = closing[[3]]
acf(SRNE)
pacf(SRNE)
SRNE30 = arimaFunction(SRNE, 30)
SRNE30
HW.SRNE30 = Holt(SRNE, 30)
HW.SRNE30
library(tibble)
library(dplyr)
ccA = read.csv("ccA.csv")
ccB = read.csv("ccB.csv")
setwd("C:/Users/Duker/Desktop/Fall 2020/CS 614/Class Work/Activity 3")
(tibble)
library(tibble)
library(dplyr)
ccA = read.csv("ccA.csv")
ccB = read.csv("ccB.csv")
gdp = read.csv("gdp.csv")
str(ccA)
str(ccB)
str(gdp)
#5)
df = merge(ccA, ccB, all = TRUE)
str(df)
#6)
df2 = cbind(df, gdp)
str(df2)
#5)
df = merge(ccA, ccB, all = TRUE)
str(df)
#6)
df2 = cbind(df, gdp)
str(df2)
#7)
df2 %>%
filter(year > 1980, gdp > 20000)
View(df2)
#7)
filter_df2 = df2 %>%
filter(year > 1980, gdp > 20000)
View(filter_df2)
#8)
df3 = data.frame()
years = unique(df2$year)
for (i in years){
yearlyTable = df2 %>%
filter(year == i)
medianGDP = median(yearlyTable$gdp)
for (gdp in yearlyTable$gdp){
delta_list = c()
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
index = which(delta_list == min(delta_list))
df3 = rbind(df3, yearlyTable[index,])
}
}
View(df3)
n = NULL
delta_list = c()
yearlyTable = df2 %>%
filter(year == 2007)
View(yearlyTable)
medianGDP = median(yearlyTable$gdp)
for (gdp in yearlyTable$gdp){
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
}
index = which(delta_list == min(delta_list))
yearlyTable[index,]
View(df3)
unique(df3)
library(tibble)
library(dplyr)
ccA = read.csv("ccA.csv")
ccB = read.csv("ccB.csv")
gdp = read.csv("gdp.csv")
str(ccA)
str(ccB)
str(gdp)
#5)
df = merge(ccA, ccB, all = TRUE)
str(df)
#6)
df2 = cbind(df, gdp)
str(df2)
# country variable type is factor???
#7)
filter_df2 = df2 %>%
filter(year > 1980, gdp > 20000)
#8)
df3 = data.frame()
years = unique(df2$year)
for (i in years){
yearlyTable = df2 %>%
filter(year == i)
medianGDP = median(yearlyTable$gdp)
for (gdp in yearlyTable$gdp){
delta_list = c()
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
index = which(delta_list == min(delta_list))
df3 = rbind(df3, yearlyTable[index,])
}
}
unique(df3)
# n = NULL
#
# delta_list = c()
#
# yearlyTable = df2 %>%
#   filter(year == 2007)
#
# medianGDP = median(yearlyTable$gdp)
#
# for (gdp in yearlyTable$gdp){
#   delta = abs(gdp - medianGDP)
#   delta_list = append(delta_list, delta)
# }
#
# index = which(delta_list == min(delta_list))
# yearlyTable[index,]
#
# n = rbind(n, yearlyTable[index,])
# n
unique(df3)
View(df3)
#8)
df3 = data.frame()
years = unique(df2$year)
for (i in years){
yearlyTable = df2 %>%
filter(year == i)
medianGDP = median(yearlyTable$gdp)
delta_list = c()
for (gdp in yearlyTable$gdp){
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
index = which(delta_list == min(delta_list))
df3 = rbind(df3, yearlyTable[index,])
}
}
unique(df3)
n = NULL
delta_list = c()
yearlyTable = df2 %>%
filter(year == 1952)
medianGDP = median(yearlyTable$gdp)
for (gdp in yearlyTable$gdp){
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
}
index = which(delta_list == min(delta_list))
yearlyTable[index,]
n = rbind(n, yearlyTable[index,])
n
delta_list = c()
yearlyTable = df2 %>%
filter(year == 1957)
medianGDP = median(yearlyTable$gdp)
for (gdp in yearlyTable$gdp){
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
}
index = which(delta_list == min(delta_list))
yearlyTable[index,]
n = rbind(n, yearlyTable[index,])
n
years
#8)
df3 = data.frame()
years = unique(df2$year)
for (i in years){
yearlyTable = df2 %>%
filter(year == i)
medianGDP = median(yearlyTable$gdp)
delta_list = c()
for (gdp in yearlyTable$gdp){
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
}
index = which(delta_list == min(delta_list))
df3 = rbind(df3, yearlyTable[index,])
}
unique(df3)
#9)
continents = unique(df2$continent)
df4 = data.frame()
#9)
continents = unique(df2$continent)
df4 = data.frame()
for (ii in continents){
yearlyTable = df2 %>%
filter(continent == ii)
medianGDP = median(yearlyTable$gdp)
delta_list = c()
for (gdp in yearlyTable$gdp){
delta = abs(gdp - medianGDP)
delta_list = append(delta_list, delta)
}
index = which(delta_list == min(delta_list))
df4 = rbind(df4, yearlyTable[index,])
}
unique(df4)
