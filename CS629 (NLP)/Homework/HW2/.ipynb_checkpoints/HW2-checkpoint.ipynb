{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Area</th>\n",
       "      <th>Population</th>\n",
       "      <th>Flora</th>\n",
       "      <th>Endemism</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>14.300</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Albania</td>\n",
       "      <td>42.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2382.0</td>\n",
       "      <td>21.300</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>N.Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Angola</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>8.500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Latitude    Area  Population   Flora  Endemism Continent\n",
       "1  Afghanistan      30.0   636.0      14.300  3000.0     0.270      Asia\n",
       "3      Albania      42.0    29.0       3.000  3200.0     0.008    Europe\n",
       "4      Algeria      35.0  2382.0      21.300  3139.0     0.080  N.Africa\n",
       "5      Andorra      42.0     0.5       0.034  1000.0     0.000    Europe\n",
       "6       Angola      25.0  1247.0       8.500  5000.0     0.250    Africa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worldcsv = pd.read_csv(\"worldfloras.csv\")\n",
    "worldcsv = worldcsv.dropna()\n",
    "worldcsv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = worldcsv.Country\n",
    "def get_countries(pattern):\n",
    "    boolean = countries.str.contains(pattern, regex=True)\n",
    "    print(list(countries[boolean]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Denmark', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Ethiopia']\n"
     ]
    }
   ],
   "source": [
    "get_countries(r'^[DE]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New Caledonia', 'New Zealand']\n"
     ]
    }
   ],
   "source": [
    "get_countries(r'^New')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cyprus', 'Syria']\n"
     ]
    }
   ],
   "source": [
    "get_countries(r'^.y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Norway', 'Sicily', 'Turkey']\n"
     ]
    }
   ],
   "source": [
    "get_countries(r'^.{5}y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Czechoslovakia', 'Liechtenstein', 'Seychelles']\n"
     ]
    }
   ],
   "source": [
    "get_countries(r'^.{3}c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet = open('hamlet.txt', 'r')\n",
    "hamlet_content = hamlet.read()\n",
    "text1000 = hamlet_content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', 'Gutenberg', 'EBook', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', 'youâ', 'll', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'ebook', 'Title', 'Hamlet', 'Author', 'William', 'Shakespeare', 'Release', 'Date', 'November', '1998', 'EBook', '1524', 'Last', 'Updated', 'September', '30', '2019', 'Language', 'English', 'Character', 'set', 'encoding', 'UTF', '8', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'HAMLET', 'This', 'etext', 'was', 'prepared', 'by', 'Dianne', 'Bean', 'THE', 'TRAGEDY', 'OF', 'HAMLET', 'PRINCE', 'OF', 'DENMARK', 'by', 'William', 'Shakespeare', 'Contents', 'ACT', 'I', 'Scene', 'I', 'Elsinore', 'A', 'platform', 'before', 'the', 'Castle', 'Scene', 'II', 'Elsinore', 'A', 'room', 'of', 'state', 'in', 'the', 'Castle', 'Scene', 'III', 'A', 'room', 'in', 'Poloniusâ', 's', 'h'] 10\n"
     ]
    }
   ],
   "source": [
    "wordToken = r'\\w+' # Find all words\n",
    "matches = re.findall(wordToken, text1000)\n",
    "print(matches, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg EBook of Hamlet, by William Shakespeare\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no\n",
      "restrictions whatsoever\n",
      "  You may copy it, give it away or re-use it\n",
      "under the terms of the Project Gutenberg License included with this\n",
      "eBook or online at www\n",
      "gutenberg\n",
      "org\n",
      "  If you are not located in the\n",
      "United States, youâ€™ll have to check the laws of the country where you\n",
      "are located before using this ebook\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Title: Hamlet\n",
      "\n",
      "Author: William Shakespeare\n",
      "\n",
      "Release Date: November 1998 [EBook #1524]\n",
      "Last Updated: September 30, 2019\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK HAMLET ***\n",
      "\n",
      "\n",
      "\n",
      "This etext was prepared by Dianne Bean\n",
      "\n",
      "\n",
      "\n",
      "THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "ACT I\n",
      "Scene I\n",
      " Elsinore\n",
      " A platform before the Castle\n",
      "\n",
      "Scene II\n",
      " Elsinore\n",
      " A room of state in the Castle\n",
      "Scene III\n",
      " A room in Poloniusâ€™s h\n"
     ]
    }
   ],
   "source": [
    "end_pattern = re.compile(r'[.?!]')\n",
    "matches = re.split(end_pattern, text1000)\n",
    "for i in matches:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', 'Gutenberg', 'EBook', 'of', 'Hamlet', ',', 'by', 'William', 'Shakespeare', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', '.', 'You', 'may', 'copy', 'it', ',', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org', '.', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', ',', 'youâ€™ll', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'ebook', '.', 'Title', ':', 'Hamlet', 'Author', ':', 'William', 'Shakespeare', 'Release', 'Date', ':', 'November', '1998', '[', 'EBook', '#', '1524', ']', 'Last', 'Updated', ':', 'September', '30', ',', '2019', 'Language', ':', 'English', 'Character', 'set', 'encoding', ':', 'UTF-8', '***', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'HAMLET', '***', 'This', 'etext', 'was', 'prepared', 'by', 'Dianne', 'Bean', '.', 'THE', 'TRAGEDY', 'OF', 'HAMLET', ',', 'PRINCE', 'OF', 'DENMARK', 'by', 'William', 'Shakespeare', 'Contents', 'ACT', 'I', 'Scene', 'I.', 'Elsinore', '.', 'A', 'platform', 'before', 'the', 'Castle', '.', 'Scene', 'II', '.', 'Elsinore', '.', 'A', 'room', 'of', 'state', 'in', 'the', 'Castle', 'Scene', 'III', '.', 'A', 'room', 'in', 'Poloniusâ€™s', 'h']\n"
     ]
    }
   ],
   "source": [
    "nltk_words = word_tokenize(text1000)\n",
    "print(nltk_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Project Gutenberg EBook of Hamlet, by William Shakespeare\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no\n",
      "restrictions whatsoever.\n",
      "You may copy it, give it away or re-use it\n",
      "under the terms of the Project Gutenberg License included with this\n",
      "eBook or online at www.gutenberg.org.\n",
      "If you are not located in the\n",
      "United States, youâ€™ll have to check the laws of the country where you\n",
      "are located before using this ebook.\n",
      "Title: Hamlet\n",
      "\n",
      "Author: William Shakespeare\n",
      "\n",
      "Release Date: November 1998 [EBook #1524]\n",
      "Last Updated: September 30, 2019\n",
      "\n",
      "Language: English\n",
      "\n",
      "Character set encoding: UTF-8\n",
      "\n",
      "*** START OF THIS PROJECT GUTENBERG EBOOK HAMLET ***\n",
      "\n",
      "\n",
      "\n",
      "This etext was prepared by Dianne Bean.\n",
      "THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      "ACT I\n",
      "Scene I. Elsinore.\n",
      "A platform before the Castle.\n",
      "Scene II.\n",
      "Elsinore.\n",
      "A room of state in the Castle\n",
      "Scene III.\n",
      "A room in Poloniusâ€™s h\n"
     ]
    }
   ],
   "source": [
    "nltk_sent = sent_tokenize(text1000)\n",
    "for i in nltk_sent:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Todd', 'Gurley', 'II', '@TG3II', '·', 'Feb', '7', 'Should', 'the', 'NFL', 'just', 'retire', '#12', 'in', 'the', 'future', '?']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweets = ['Todd Gurley II @TG3II ·Feb 7 Should the NFL just retire #12 in the future?']\n",
    "tknzr = TweetTokenizer()\n",
    "tweet_tokens = [tknzr.tokenize(i) for i in tweets]\n",
    "print(tweet_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
